{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27256252-7f3c-4d29-bfa5-828360b363e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/farhatahmed/.local/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/farhatahmed/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: torchvision in /Users/farhatahmed/.local/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /Users/farhatahmed/.local/lib/python3.12/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/farhatahmed/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991334fa-37b4-4f8c-8383-7ca8a7125d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/age_gender.csv')\n",
    "\n",
    "df2 = pd.read_csv('data/Faces_ Age Detection from Images/faces/train.csv')\n",
    "\n",
    "df3 = pd.read_csv('data/Faces_ Age Detection from Images/faces/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11439f5d-ce34-47cf-8bdc-f88135530f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23700</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170120221920654.jpg.chip.jpg</td>\n",
       "      <td>127 100 94 81 77 77 74 99 102 98 128 145 160 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23701</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20170120134639935.jpg.chip.jpg</td>\n",
       "      <td>23 28 32 35 42 47 68 85 98 103 113 117 130 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20170110182418864.jpg.chip.jpg</td>\n",
       "      <td>59 50 37 40 34 19 30 101 156 170 177 184 187 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20170117195405372.jpg.chip.jpg</td>\n",
       "      <td>45 108 120 156 206 197 140 180 191 199 204 207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170110182052119.jpg.chip.jpg</td>\n",
       "      <td>156 161 160 165 170 173 166 177 183 191 187 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender                        img_name  \\\n",
       "23700   99          0       1  20170120221920654.jpg.chip.jpg   \n",
       "23701   99          1       1  20170120134639935.jpg.chip.jpg   \n",
       "23702   99          2       1  20170110182418864.jpg.chip.jpg   \n",
       "23703   99          2       1  20170117195405372.jpg.chip.jpg   \n",
       "23704   99          0       1  20170110182052119.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "23700  127 100 94 81 77 77 74 99 102 98 128 145 160 1...  \n",
       "23701  23 28 32 35 42 47 68 85 98 103 113 117 130 129...  \n",
       "23702  59 50 37 40 34 19 30 101 156 170 177 184 187 1...  \n",
       "23703  45 108 120 156 206 197 140 180 191 199 204 207...  \n",
       "23704  156 161 160 165 170 173 166 177 183 191 187 18...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e51962da-7a79-4c33-8929-62929ea173a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/age_gender.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder('data/age_gender.csv', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "821477af-1ea0-409e-a83d-287006c96839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform = None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.class2index = {\"cat\":0, \"dog\":1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df[index, \"FILENAME\"]\n",
    "        label = self.class2index[self.df[index, \"LABEL\"]]\n",
    "        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce354b9f-7e9b-4c49-8492-5f3e12902735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def age_to_range(age):\n",
    "    if age < 5:\n",
    "        return \"0-4\"\n",
    "    elif age < 10:\n",
    "        return \"5-9\"\n",
    "    elif age < 15:\n",
    "        return \"10-14\"\n",
    "    elif age < 20:\n",
    "        return \"15-19\"\n",
    "    elif age < 25:\n",
    "        return \"20-24\"\n",
    "    elif age < 30:\n",
    "        return \"25-29\"\n",
    "    elif age < 35:\n",
    "        return \"30-34\"\n",
    "    elif age < 40:\n",
    "        return \"35-39\"\n",
    "    elif age < 45:\n",
    "        return \"40-44\"\n",
    "    elif age < 50:\n",
    "        return \"45-49\"\n",
    "    elif age < 55:\n",
    "        return \"50-54\"\n",
    "    elif age < 60:\n",
    "        return \"55-59\"\n",
    "    elif age < 65:\n",
    "        return \"60-64\"\n",
    "    elif age < 70:\n",
    "        return \"65-69\"\n",
    "    elif age < 75:\n",
    "        return \"70-74\"\n",
    "    elif age < 80:\n",
    "        return \"75-79\"\n",
    "    elif age < 85:\n",
    "        return \"80-84\"\n",
    "    elif age < 90:\n",
    "        return \"85-89\"\n",
    "    elif age < 95:\n",
    "        return \"90-94\"\n",
    "    elif age < 100:\n",
    "        return \"95-99\"\n",
    "    elif age < 105:\n",
    "        return \"100-104\"\n",
    "    elif age < 110:\n",
    "        return \"105-109\"\n",
    "    elif age < 115:\n",
    "        return \"110-114\"\n",
    "    elif age < 120:\n",
    "        return \"115-119\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9c530d4-3e42-4f16-8558-e96454997176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  ethnicity  gender                        img_name  \\\n",
      "1372  116          0       1  20170120134921760.jpg.chip.jpg   \n",
      "1373  116          2       1  20170112220255503.jpg.chip.jpg   \n",
      "1374  116          3       1  20170120134744096.jpg.chip.jpg   \n",
      "1375  116          0       1  20170112213001988.jpg.chip.jpg   \n",
      "\n",
      "                                                 pixels  \n",
      "1372  81 91 101 106 113 115 117 121 122 122 122 128 ...  \n",
      "1373  207 200 197 181 186 174 184 185 162 164 164 16...  \n",
      "1374  133 147 143 150 206 60 45 101 144 76 25 85 114...  \n",
      "1375  105 86 95 135 159 150 147 147 153 117 148 160 ...  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('age_gender.csv')\n",
    "\n",
    "df_over_100 = df1[df1['age'] == max(df1['age'])]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(df_over_100)\n",
    "\n",
    "\n",
    "# Apply function to the 'age' column\n",
    "df1[\"age_range\"] = df1[\"age\"].apply(age_to_range)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f2f5d39-eaa9-4f93-b658-03d98e956f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = CustomDataset(\"data/age_gender.csv\")\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('age_gender.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply function to the 'age' column\n",
    "df1[\"age_range\"] = df1[\"age\"].apply(age_to_range)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1['pixels']\n",
    "y = df1['age_range']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X,y , random_state=104,test_size=0.3, shuffle=True)\n",
    "\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "  X_test,y_test, random_state=104,test_size=0.5, shuffle=True)\n",
    "\n",
    "train = pd.DataFrame(X_train.copy())\n",
    "train['label'] = y_train.values \n",
    "\n",
    "test = pd.DataFrame(X_test.copy())\n",
    "test['label'] = y_test.values \n",
    "test.head()\n",
    "\n",
    "val = pd.DataFrame(X_val.copy())\n",
    "val['label'] = y_val.values \n",
    "val.head()\n",
    "\n",
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)\n",
    "df_val = pd.DataFrame(val)\n",
    "df_train.to_csv('age_data/age-train.csv', index=False)\n",
    "df_test.to_csv('age_data/age-test.csv', index=False)\n",
    "df_test.to_csv('age_data/age-val.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0cdc744-b068-4d00-a3da-064898b0bd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 119 86 108 108 119 135 130 133 141 153 154...</td>\n",
       "      <td>60-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35 28 41 48 56 70 118 168 176 187 185 192 188 ...</td>\n",
       "      <td>15-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166 165 181 186 193 203 198 197 201 201 205 21...</td>\n",
       "      <td>65-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40 35 46 60 109 113 125 135 150 163 170 172 17...</td>\n",
       "      <td>30-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42 60 105 155 175 186 198 210 217 219 224 223 ...</td>\n",
       "      <td>35-39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels  label\n",
       "0  100 119 86 108 108 119 135 130 133 141 153 154...  60-64\n",
       "1  35 28 41 48 56 70 118 168 176 187 185 192 188 ...  15-19\n",
       "2  166 165 181 186 193 203 198 197 201 201 205 21...  65-69\n",
       "3  40 35 46 60 109 113 125 135 150 163 170 172 17...  30-34\n",
       "4  42 60 105 155 175 186 198 210 217 219 224 223 ...  35-39"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = pd.read_csv('age-train.csv')\n",
    "\n",
    "df1.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "074d7e4b-c1fa-4da6-8d74-ed82e22b3c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USE_GPU = True\n",
    "num_class = 100\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "94f0f228-d9fc-486b-9746-c3d8aeb8a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Assuming 'pixels' column contains space-separated pixel values as a string\n",
    "        pixel_str = self.data.iloc[idx][\"pixels\"]\n",
    "        pixels = np.array(pixel_str.split(), dtype=np.float32)  # Convert to NumPy array\n",
    "        pixels = torch.tensor(pixels).view(1, 48, 48)  # Reshape (assuming 48x48 image) #change if colored)\n",
    "        \n",
    "        # Assuming 'age' column contains the label\n",
    "\n",
    "        self.age_ranges = [\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\",\n",
    "                   \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n",
    "                   \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80-84\", \"85-89\",\n",
    "                   \"90-94\", \"95-100\"]\n",
    "\n",
    "        # Create a dictionary to map each age range to an index\n",
    "        self.age_to_index = {age: i for i, age in enumerate(self.age_ranges)}\n",
    "        age_range = self.data.iloc[idx][\"label\"]  # Assume the column already contains age ranges\n",
    "        age_index = self.age_to_index[age_range]  # Get the index\n",
    "        age_onehot = F.one_hot(torch.tensor(age_index), num_classes=len(self.age_ranges)).float()\n",
    "        \n",
    "        return pixels, age_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5760383-60a8-47c7-9431-817196896a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2e0ac6e7-6b8d-43a9-b158-79eb9073cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 48, 48])\n",
      "torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"age-train.csv\"  # Update this to your actual file path\n",
    "\n",
    "dataset = AgeDataset(csv_file_path)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example usage\n",
    "for images, ages in dataloader:\n",
    "    print(images.shape)  # Expected: (batch_size, 1, 48, 48)\n",
    "    print(ages.shape)    # Expected: (batch_size,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "189f327c-cf59-47ab-ab3a-5d85d59a2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train = AgeDataset(\"age-train.csv\")\n",
    "loader_train = DataLoader(age_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "age_val = AgeDataset(\"age-val.csv\")\n",
    "loader_val = DataLoader(age_val, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "age_test = AgeDataset(\"age-test.csv\")\n",
    "loader_test = DataLoader(age_test, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "088d6a84-2d9a-4c95-a223-f2aa35ea3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):    \n",
    "    # build the constructor\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "    # make predictions\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "392754ca-6c39-4410-aa2f-3fcbfc920bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "n_inputs = 48*48 # makes a 1D vector of 784\n",
    "n_outputs = 20\n",
    "log_regr = LogisticRegression(n_inputs, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92ea72-227f-4de1-a4ab-9a0cfff42f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the optimizer\n",
    "optimizer = torch.optim.SGD(log_regr.parameters(), lr=0.001)\n",
    "# defining Cross-Entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    " \n",
    "epochs = 50\n",
    "Loss = []\n",
    "acc = []\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(loader_train):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = log_regr(images.view(-1, 48*48))\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    Loss.append(loss.item())\n",
    "    correct = 0\n",
    "    for images, labels in loader_test:\n",
    "        outputs = log_regr(images.view(-1, 48*48))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "    accuracy = 100 * (correct.item()) / len(test_dataset)\n",
    "    acc.append(accuracy)\n",
    "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789aa254-f984-4a5f-9d5c-73264556a393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
